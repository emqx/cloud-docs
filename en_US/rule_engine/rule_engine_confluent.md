# Bridge device data to Confluent Cloud using the Rule Engine

In this article, we will simulate temperature and humidity data and report these data to EMQX Cloud via the MQTT protocol and then use the EMQX Cloud rules engine to dump the data into Confluent Cloud.

Before you start, you need to complete the following operations:
* Deployments have already been created on EMQX Cloud (EMQX Cluster).
* This feature is available for professional deployment
* There are three types of Confluent Cloud cluster you could choose:
  * For basic and standard cluster, please open the NAT first.
  * For dedicated cluster, please complete [Peering Connection Creation](../deployments/vpc_peering.md) first, all IPs mentioned below refer to the intranet IP of the resource.


  <div style="position: relative; padding: 30% 45%;">
  <iframe style="position: absolute; width: 100%; height: 100%; left: 0; top: 0;" src="https://www.youtube.com/embed/jLn0q8xf-1Y" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>
  </div>


## Confluent Cloud Configuration

### Create a cluster

*  Login to the Confluent Cloud console and create a cluster.
*  At this time, we select the dedicated cluster as an example.

   ![cluster](./_assets/confluent_cluster.png)

*  Select region/zones (make sure the deployment region matches the region of the Confluent Cloud)

   ![region](./_assets/confluent_region.png)

*  Select VPC Peering for the networking so this cluster could be accessed only by vpc peering connection. 

   ![nat](./_assets/confluent_nat.png)

*  Specify a CIDR block for the cluster and click `Conttinue`

*  Based on your needs, choose the way to manage the encryption key
   
   ![security](./_assets/confluent_security.png)

*  After binding the card, you are ready to launch the cluster

### Manage the cluster using Confluent Cloud CLI

Now that you have a cluster up and running in Confluent Cloudï¼Œ you can manage it using the Confluent Cloud CLI. Here are some basic commands that you could use with Confluent Cloud CLI.

#### Install the Confluent Cloud CLI

```bash
curl -L --http1.1 https://cnfl.io/ccloud-cli | sh -s -- -b /usr/local/bin
```

If you already have the CLI installed, you could update it by:

```bash
ccloud update
```

#### Log in to your account

```bash
ccloud login --save
```

#### Select the environment

```bash
ccloud environment use env-v9y0p
```

#### Select the cluster

```bash
ccloud kafka cluster use lkc-djr31
```

#### Use an API key and secret

If you have an existing API key that you'd like to use, add it to the CLI by:

```bash
ccloud api-key store --resource lkc-djr31
Key: <API_KEY>
Secret: <API_SECRET>
```

If you don't have the API key and secret, you can create one by:

```bash
ccloud api-key create --resource lkc-djr31
```

After add them to teh CLI, you could use the API key and secret by:

```bash
ccloud api-key use "API_Key" --resource lkc-djr31
```

#### Create a topic

```bash
ccloud kafka topic create topic-name
```

You could check the topic list by:

```bash
ccloud kafka topic list
```

#### Produce messages to the topic

```bash
ccloud kafka topic produce topic-name
```

#### Consume messages from the topic

```bash
ccloud kafka topic consume -b topic-name
```

### Build VPC Peering Connection with the deployment

After the cluster has been created, we should add peering

*  Go to the `Networking` section of the `Cluster settings` page and click on the `Add Peering` button.

   ![addPeering](./_assets/confluent_addPeering.png)

*  Fill in the vpc information. (You could get the information from `VPC Peering` section of the deployment console)
   
   ![vpc_info](./_assets/confluent_vpc1.png)
   
   ![vpc_info](./_assets/confluent_vpc2.png)

*  When the connection status is `Inactive`, go back to the deployment console to accept the peering request. Fill in the vpc information of the confluent cloud cluster and click `Confirm`. When the vpc status turns to `running`, you successfully create the vpc peering connection. 

   ![vpc_info](./_assets/confluent_vpc2.png)
   
   ![vpc](./_assets/confluent_finish.png)
   

## EMQX Cloud rule engine configuration

Go to the `Rule Engine` page

1. Create a new resource

   Click on the `+ New`  button in the `Resources` section and select `Kafka` as the resource type. Fill in the Conflent Cloud information you have just created and click Test. If you get an error, instantly check that the database configuration is correct.
   ![create resource](./_assets/confluent_create_resource.png)

2. Create a new rule

   Click on the `+ New`  button in the `Rules` section. Enter the following rule to match the SQL statement.  In the following rule we read the time `up_timestamp` when the message is reported, the client ID, the message body (Payload) from the `temp_hum/emqx` topic and the temperature and humidity from the message body respectively.

   ```sql
   SELECT 
   
   timestamp as up_timestamp, clientid as client_id, payload.temp as temp, payload.hum as hum
   
   FROM
   
   "temp_hum/emqx"
   ```
   ![rule sql](./_assets/sql_test.png)

3. Create a response action 
   
   Click on the `Add Action` toward the bottom of the page and select action type as `Data Forwarding` and `Bridge Data to Kafka`. Select the resource created in the first step and fill in the following data:

   Kafka topic: emqx
   Message content template:
   
   ```
   {"up_timestamp": ${up_timestamp}, "client_id": ${client_id}, "temp": ${temp}, "hum": ${hum}}
   ```
   ![kafka action](./_assets/confluent_action.png)

5. View rules monitoring
   
   Go back to the `Rule Engine` page to monitor the rule
   ![monitor](./_assets/view_monitor_confluent.png)

## Test

1. Use [MQTT X](https://mqttx.app/) to simulate temperature and humidity data reporting

   You need to replace broker.emqx.io with the created deployment [connection address](../deployments/view_deployment.md), and add [client authentication information](../deployments/auth.md) to the EMQX Dashboard.
   ![MQTTX](./_assets/mqttx_publish.png)
   
2. View data dump results

    ```bash
    # Go to the Kafka instance and view the temp_hum topic
    ccloud kafka topic consume -b temp_hum
    ```
   ![kafka](./_assets/confluent_result.png)
